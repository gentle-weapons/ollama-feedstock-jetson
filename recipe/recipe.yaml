context:
  version: "0.15.6"
  cuda: ${{ "true" if cuda_compiler_version != "None" else "" }}
  cuda_build_string: cuda_${{ cuda_compiler_version | version_to_buildstring }}
  jetpack: ${{ "true" if jetpack_version != "None" else "" }}
  jetpack_build_string: jetpack${{ jetpack_version }}
  string_prefix: ${{ jetpack_build_string if jetpack else (cuda_build_string if cuda else "cpu_") }}
  build_number: 0

package:
  name: ollama
  version: ${{ version }}

source:
  - if: jetpack
    then:
      - url: https://github.com/ollama/ollama/releases/download/v${{ version }}/ollama-linux-arm64.tar.zst
        sha256: 3deaeccfab078e051956d9f699e30a29b7c1227813b3e690faecec710cb09d12
        target_directory: ollama-bin
      - url: https://github.com/ollama/ollama/releases/download/v${{ version }}/ollama-linux-arm64-jetpack${{ jetpack_version }}.tar.zst
        sha256: 1ac3f73c26a5c8f250b1a4fb0603aa1c1a6e35757e172efa106a82b3a48a2b00
        target_directory: ollama-jetpack-libs
    else:
      url: https://github.com/ollama/ollama/archive/refs/tags/v${{ version }}.tar.gz
      sha256: c5628fd19cd987f94f5ad7ea1df0aa312c8185677e6d88fadd08e5f650586371
      patches:
        - 0001-ggml-cuda-depends-on-ggml-base.patch
        - if: linux
          then: 0002-Add-defines-missing-in-glibc-2.17.patch

build:
  number: ${{ build_number }}
  string: ${{ string_prefix }}h${{ hash }}_${{ build_number }}
  variant:
    use_keys:
      - ${{ "cuda" if cuda }}
      - ${{ "jetpack" if jetpack }}
    down_prioritize_variant: ${{ 1 if cuda == "true" or jetpack == "true" else 0 }}
  script:
    - if: win
      then: [build.bat]
      else: [build.sh]
  skip:
    - cuda and match(cuda_compiler_version, "<12")
    - jetpack and not (linux and aarch64)
    - jetpack and cuda

requirements:
  build:
    - if: not jetpack
      then:
        - ${{ compiler('go-cgo') }}
        - cmake
        - make
        - go-licenses ~= 1.6
    - if: win
      then:
        - ${{ stdlib('m2w64_c') }}
        - ${{ compiler('m2w64_cxx') }}
    - if: not win and not jetpack
      then:
        - ${{ stdlib('c') }}
        - ${{ compiler('cxx') }}
    - if: cuda
      then:
        - ${{ compiler('cuda') }}
        - cuda-version ==${{ cuda_compiler_version }}
  host:
    - if: cuda
      then:
        - cuda-version ==${{ cuda_compiler_version }}
        - libcublas-dev
  run:
    - if: jetpack
      then:
        - __glibc >=2.31
  run_constraints:
    - if: jetpack
      then:
        - __cuda >=12.0
  ignore_run_exports:
    from_package:
      - if: cuda
        then: libcublas-dev

tests:
  - script:
      - ollama --version

about:
  homepage: https://ollama.com/
  repository: https://github.com/ollama/ollama
  documentation: https://github.com/ollama/ollama
  summary: Ollama CLI
  description: |
    Ollama is an easy way to get local language models running on your computer through a command-line interface.
  license: MIT
  license_file:
    - if: not jetpack
      then:
        - LICENSE
        - license-files/

extra:
  recipe-maintainers:
    - jmakovicka
    - sodre
    - benmoss
